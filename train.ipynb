{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import warnings\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "ct_utils = importlib.import_module('ct_utils');\n",
    "\n",
    "warnings.filterwarnings(\"ignore\");\n",
    "print('Pandas version:', pd.__version__);\n",
    "print('Numpy version:', np.__version__);\n",
    "print('MatplotLib version:', mpl.__version__);\n",
    "print('Sklearn version:', sklearn.__version__);\n",
    "print('Seaborn version:', sns.__version__);\n",
    "print('PyTorch version:', torch.__version__);\n",
    "print('Optuna version:', optuna.__version__);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the datasets for train and test\n",
    "\n",
    "\n",
    "### The following lists need to be specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "melloddy_emb_cols = [\"melloddy_emb_\" + str(i) for i in range(2000)]; #columns specifying the structural encoding\n",
    "\n",
    "#additional input columns (e.g. the species) have to be added to the global features list\n",
    "global_features = melloddy_emb_cols;\n",
    "\n",
    "time_cols = [ \"time_\" + str(i) for i in range(100)]; #timestamps of the measurments\n",
    "conc_cols_po = [ \"conc_po_\" + str(i) for i in range(100)]; # po concentration measurments in nM \n",
    "conc_cols_iv = [ \"conc_iv_\" + str(i) for i in range(100)]; # iv concentration measurments in nM \n",
    "\n",
    "target_features =  time_cols + conc_cols_po + conc_cols_iv;\n",
    "\n",
    "dose_column = \"Dose\" # mg/kg\n",
    "mass_column = \"Average Mass\" # g/mol\n",
    "species_colum = \"Species\" # Rat\n",
    "\n",
    "input_data = \"dummy.csv\"\n",
    "output_folder = \"tmp_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate dummy data\n",
    "df = pd.DataFrame();\n",
    "df[melloddy_emb_cols+time_cols+conc_cols_po+conc_cols_iv + [\"Dose\",\"Average Mass\"]] = np.random.rand(1000,2000+300+2);\n",
    "df[species_colum] = [\"Rat\"]*df.shape[0];\n",
    "df.to_csv(\"dummy.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "# each row is one experiment, i.e. one PK study\n",
    "df = pd.read_csv(input_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Dose_trf\"] = ct_utils.recalc_dose(df[dose_column].to_numpy(dtype=float), df[mass_column].to_numpy(), df[species_colum].to_numpy());\n",
    "df = df.dropna(subset = time_cols + conc_cols_po + conc_cols_iv, how=\"all\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df.iloc[int(0.8*df.shape[0]):];\n",
    "df_train = df.iloc[:int(0.8*df.shape[0])];\n",
    "df_val = df_test.iloc[int(0.75*df_test.shape[0]):];\n",
    "df_test = df_test.iloc[:int(0.75*df_test.shape[0])];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-01T14:18:53.416454Z",
     "iopub.status.busy": "2024-02-01T14:18:53.416191Z",
     "iopub.status.idle": "2024-02-01T14:18:53.427987Z",
     "shell.execute_reply": "2024-02-01T14:18:53.427151Z",
     "shell.execute_reply.started": "2024-02-01T14:18:53.416436Z"
    },
    "tags": []
   },
   "source": [
    "## Scale (not necessary when only MELLODDY embeddings used as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_normed = [\"Dose_trf\"]\n",
    "\n",
    "sc = StandardScaler()\n",
    "final_train_scaler = sc.fit(df_train[features_to_be_normed]);\n",
    "import pickle\n",
    "scalerfile = output_folder + '/scaler.sav'\n",
    "pickle.dump(final_train_scaler, open(scalerfile, 'wb'))\n",
    "final_train_scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "df_train[features_to_be_normed] = final_train_scaler.transform(df_train[features_to_be_normed]);\n",
    "df_val[features_to_be_normed] = final_train_scaler.transform(df_val[features_to_be_normed]);\n",
    "df_test[features_to_be_normed] = final_train_scaler.transform(df_test[features_to_be_normed]);\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    " \n",
    "if torch.cuda.is_available():\n",
    "    print('use GPU');\n",
    "    device='cuda';\n",
    "else:\n",
    "    print('use CPU');\n",
    "    device='cpu';\n",
    "    \n",
    "mod = importlib.import_module('DeepCt');\n",
    "importlib.reload(mod);\n",
    "DeepCt = getattr(mod, 'DeepCt');\n",
    "\n",
    "ct_utils = importlib.import_module('ct_utils');\n",
    "importlib.reload(ct_utils);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data( global_features, targets):\n",
    "\n",
    "    global_feat_list = [];\n",
    "    for i in range(targets.shape[0]):\n",
    "                global_feat_list.append(torch.from_numpy(global_features[i,:])); \n",
    "        \n",
    "    return  global_feat_list, targets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(sample):\n",
    "    global_feats, labels = map(list,zip(*sample));\n",
    "    global_feats = torch.stack([torch.tensor(tmp) for tmp in global_feats]);\n",
    "\n",
    "    return  global_feats, torch.tensor(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_final(params, verbose=True):\n",
    "    import copy\n",
    "    print(params);\n",
    "    model = DeepCt( global_feats=len(global_features), predictor_dropout=params[\"dropout\"], num_layers=params[\"depth\"],\n",
    "                                       n_tasks=len(ct_utils.targets_combined), predictor_hidden_feats=params[\"predictor_hidden_feats\"]);\n",
    "\n",
    "    model = model.to(device);\n",
    "\n",
    "    global_feat_train, targets_train = get_data( df_train[global_features].to_numpy(dtype=np.float32), \n",
    "                                                                 df_train[target_features + [\"Dose_trf\"] ].to_numpy());\n",
    "    \n",
    "    global_feat_val, targets_val = get_data( df_val[global_features].to_numpy(dtype=np.float32),\n",
    "                                                           df_val[target_features + [\"Dose_trf\"] ].to_numpy());\n",
    "    if verbose:\n",
    "        print(\"Data loaded ...\");\n",
    "    \n",
    "    train_data = list(zip( global_feat_train, targets_train)).copy();\n",
    "    train_loader = DataLoader(train_data, batch_size=int(params[\"batch_size\"]), shuffle=True, collate_fn=collate, pin_memory=True, num_workers=1, drop_last=True);\n",
    "    \n",
    "    val_data = list(zip( global_feat_val, targets_val)).copy();\n",
    "    val_loader = DataLoader(val_data, batch_size=256, shuffle=False, collate_fn=collate, drop_last=False);\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=params[\"weight_decay\"]);\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.001, mode=\"triangular2\", step_size_up=2*len(train_loader),cycle_momentum=False);\n",
    "    model.train();\n",
    "\n",
    "    epoch_losses = [];\n",
    "    epoch_accuracies = [];\n",
    "    \n",
    "    #early stopping params\n",
    "    num_no_improvements = 0;\n",
    "    best_val = 10e20;\n",
    "    patience = 10;\n",
    "        \n",
    "    for epoch in range(1,100):\n",
    "        model.train();\n",
    "        epoch_loss = 0;\n",
    "        for i, (global_feats, labels) in enumerate(train_loader):\n",
    "            \n",
    "            labels = labels.to(device);\n",
    "            global_feats = global_feats.to(device);\n",
    "            \n",
    "            preds = model( global_feats);\n",
    "            \n",
    "            loss = ct_utils.L2_expcurve_and_readout_loss(preds, labels.float(), readout_weight=0.0, num_cmpts=2);\n",
    "\n",
    "            optimizer.zero_grad();\n",
    "            loss.backward();\n",
    "                        \n",
    "            optimizer.step();\n",
    "            scheduler.step();\n",
    "            \n",
    "        #######################\n",
    "        ### Valid the model ###\n",
    "        #######################\n",
    "        model.eval();\n",
    "        pred_es = np.empty(shape=[0, len(ct_utils.targets_combined)]);\n",
    "        for i, ( global_feats, labels) in enumerate(val_loader):\n",
    "            global_feats = global_feats.to(device);\n",
    "            labels = labels.to(device);\n",
    "            tmp_preds = model( global_feats);\n",
    "\n",
    "            tmp_preds = tmp_preds.cpu().detach().numpy();    \n",
    "            pred_es = np.append(pred_es, tmp_preds, axis=0);\n",
    "            \n",
    "        tmp_val = ct_utils.L2_expcurve_and_readout_loss(torch.from_numpy(pred_es), \n",
    "                                                        torch.from_numpy(df_val[target_features + [\"Dose_trf\"]].to_numpy()), \n",
    "                                                        readout_weight=0.0, num_cmpts=2);\n",
    "        \n",
    "        tmp_val = tmp_val.detach().numpy();\n",
    "        if verbose:\n",
    "            print(\"Learning rate: \" + str(optimizer.param_groups[0]['lr']));\n",
    "\n",
    "        if tmp_val < best_val:\n",
    "            num_no_improvements = 0;\n",
    "            best_val = tmp_val;\n",
    "            best_model = copy.deepcopy(model);\n",
    "        else:\n",
    "            num_no_improvements = num_no_improvements + 1;\n",
    "            if num_no_improvements>patience:\n",
    "                if verbose:\n",
    "                    print(\"Early stopping here ...\");\n",
    "                break;\n",
    "        \n",
    "        epoch_accuracies.append(tmp_val);\n",
    "        if verbose:\n",
    "            print(\"Current Test-Loss: \" + str(tmp_val));\n",
    "      \n",
    "    if verbose:\n",
    "        print(\"Best val: \" + repr(best_val));\n",
    "    \n",
    "    return best_model, best_val;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T14:44:42.570297Z",
     "iopub.status.busy": "2024-02-20T14:44:42.569970Z",
     "iopub.status.idle": "2024-02-20T15:03:57.080423Z",
     "shell.execute_reply": "2024-02-20T15:03:57.079787Z",
     "shell.execute_reply.started": "2024-02-20T14:44:42.570281Z"
    },
    "tags": []
   },
   "source": [
    "### Hyperparameter optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_trials = 3;\n",
    "study_name = \"dummy\";\n",
    "def objective(trial):\n",
    "    \n",
    "    #set the current hyperparameters\n",
    "    final_params = {'batch_size': 2**(trial.suggest_int(\"batch_size\", 4, 10, step=1)), 'depth': trial.suggest_int(\"depth\", 3, 10), 'dropout': trial.suggest_float(\"dropout\", 0.0, 0.9, step=0.05), \n",
    "                    'predictor_hidden_feats': 2**(trial.suggest_int(\"predictor_hidden_feats\", 4, 10, step=1)), 'weight_decay': trial.suggest_float(\"weight_decay\", 0.0, 0.1, step=0.01)};\n",
    "    \n",
    "    #train the model\n",
    "    model, loss = fit_final(final_params, verbose=False);\n",
    "    \n",
    "    return loss\n",
    "\n",
    "study = optuna.create_study(study_name=study_name);\n",
    "study.optimize(objective, n_trials=num_trials);\n",
    "    \n",
    "study.trials_dataframe().to_csv(\"optuna_\" + study_name + \".csv\");\n",
    "print('Best value: {} (params: {})\\n'.format(study.best_value, study.best_params));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T14:44:42.570297Z",
     "iopub.status.busy": "2024-02-20T14:44:42.569970Z",
     "iopub.status.idle": "2024-02-20T15:03:57.080423Z",
     "shell.execute_reply": "2024-02-20T15:03:57.079787Z",
     "shell.execute_reply.started": "2024-02-20T14:44:42.570281Z"
    },
    "tags": []
   },
   "source": [
    "***IMPORTANT***: batch_size as well as predictor_hidden_feats are optimized with respect to base 2. E.g. the actual batch size is 2^y when y is the result from optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T14:44:42.570297Z",
     "iopub.status.busy": "2024-02-20T14:44:42.569970Z",
     "iopub.status.idle": "2024-02-20T15:03:57.080423Z",
     "shell.execute_reply": "2024-02-20T15:03:57.079787Z",
     "shell.execute_reply.started": "2024-02-20T14:44:42.570281Z"
    },
    "tags": []
   },
   "source": [
    "### Final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "final_params = {'batch_size': 32, 'depth': 5, 'dropout': 0.3, 'predictor_hidden_feats': 256, 'weight_decay': 0.01};\n",
    "\n",
    "best_loss = 10e20;\n",
    "i = 0;\n",
    "\n",
    "while i < 10:\n",
    "    model, tmp_loss = fit_final(final_params);\n",
    "    torch.save(model.state_dict(), output_folder +  \"/weights_\" + str(i) + \".pth\");\n",
    "    i = i + 1;\n",
    "    if tmp_loss < best_loss:\n",
    "        best_loss = tmp_loss;\n",
    "        best_model = copy.deepcopy(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@deathbeds/ipydrawio": {
   "xml": ""
  },
  "kernelspec": {
   "display_name": "DeepCt",
   "language": "python",
   "name": "deepct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
